{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49a5ad69-aa47-47a7-91b6-14ee018dc697",
   "metadata": {},
   "source": [
    "### Revision_Tcell vs Bcell TEST (Bootstrapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c676244-cf94-4411-8411-0e0a4b08e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, \n",
    "    roc_auc_score, ConfusionMatrixDisplay, roc_curve, auc, precision_recall_curve,\n",
    "    balanced_accuracy_score, matthews_corrcoef\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebb1bb1-4126-415c-bc8b-0235e91c4182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available. cuda:0 will be used\n"
     ]
    }
   ],
   "source": [
    "# GPU setting\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print('GPU available.', device, 'will be used')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('GPU unavailable.', device, 'will be used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd9fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bootstrapping by patient ID\n",
    "def calculate_bootstrap_ci(y_true, y_pred, y_probs, patient_ids, n_iterations=1000, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Receives a list of patient IDs, performs patient-level bootstrapping,\n",
    "    and returns the 95% CI of key metrics as a formatted string.\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true) # NumPy array: supports 'vectorized operations' that apply conditions or perform operations on all data without loops\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "    patient_ids = np.array(patient_ids)\n",
    "\n",
    "    unique_patients = np.unique(patient_ids)\n",
    "    n_patients = len(unique_patients)\n",
    "\n",
    "    # Dictionary to save metrics\n",
    "    scores = {\n",
    "        \"Accuracy\": [], \"Balanced Accuracy\": [], \"MCC\": [],\n",
    "        \"Sensitivity\": [], \"Specificity\": [],\n",
    "        \"PPV\": [], \"NPV\": [],\n",
    "        \"F1 Score (Binary)\": [],\n",
    "        \"Precision (Binary)\": [],\n",
    "        \"AUC-ROC\": [],\n",
    "        \"AUC-PR\": [],\n",
    "        \"Precision (Weighted)\": [],\n",
    "        \"Recall (Weighted)\": [],\n",
    "        \"F1 Score (Weighted)\": []\n",
    "    }\n",
    "\n",
    "    print(f\"[INFO] Starting Patient-level Bootstrapping ({n_iterations} iterations)...\")\n",
    "\n",
    "    ## Bootstrapping Loop\n",
    "    for _ in tqdm(range(n_iterations), desc=\"Bootstrapping\"):\n",
    "        # 1. Replacement by Patients unit\n",
    "        sampled_patients = resample(unique_patients, replace=True, n_samples=n_patients)\n",
    "\n",
    "        # 2. Index collection of sampled patients\n",
    "        indices_boot = []\n",
    "        for pid in sampled_patients:\n",
    "            indices_boot.extend(np.where(patient_ids == pid)[0])\n",
    "\n",
    "        y_true_boot = y_true[indices_boot]\n",
    "        y_pred_boot = y_pred[indices_boot]\n",
    "        y_probs_boot = y_probs[indices_boot]\n",
    "\n",
    "        # Exception: Skip in cases where only one class is selected\n",
    "        if len(np.unique(y_true_boot)) < 2: \n",
    "            continue\n",
    "\n",
    "        # 3. Calculate metrics\n",
    "        scores[\"Accuracy\"].append(accuracy_score(y_true_boot, y_pred_boot))\n",
    "        scores[\"Balanced Accuracy\"].append(balanced_accuracy_score(y_true_boot, y_pred_boot))\n",
    "        scores[\"MCC\"].append(matthews_corrcoef(y_true_boot, y_pred_boot))\n",
    "        \n",
    "        # Extract TN, FP, FN, TP\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true_boot, y_pred_boot, labels=[0, 1]).ravel()\n",
    "        \n",
    "        # Sensitivity = Recall = TP / (TP + FN)\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        scores[\"Sensitivity\"].append(sensitivity)\n",
    "\n",
    "        # Specificity = TN / (TN + FP)\n",
    "        spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        scores[\"Specificity\"].append(spec)\n",
    "\n",
    "        # PPV = Precision = TP / (TP + FP)\n",
    "        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        scores[\"PPV\"].append(ppv)\n",
    "        scores[\"Precision (Binary)\"].append(ppv)\n",
    "        \n",
    "        # NPV = TN / (TN + FN)\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
    "        scores[\"NPV\"].append(npv)\n",
    "        \n",
    "        # F1 score (beta =1)\n",
    "        scores[\"F1 Score (Binary)\"].append(f1_score(y_true_boot, y_pred_boot, average='binary', zero_division=1))\n",
    "\n",
    "        scores[\"Precision (Weighted)\"].append(precision_score(y_true_boot, y_pred_boot, average='weighted', zero_division=1))\n",
    "        scores[\"Recall (Weighted)\"].append(recall_score(y_true_boot, y_pred_boot, average='weighted', zero_division=1))\n",
    "        scores[\"F1 Score (Weighted)\"].append(f1_score(y_true_boot, y_pred_boot, average='weighted', zero_division=1))\n",
    "\n",
    "        try:\n",
    "            scores[\"AUC-ROC\"].append(roc_auc_score(y_true_boot, y_probs_boot))\n",
    "\n",
    "            precision_curve, recall_curve, _ = precision_recall_curve(y_true_boot, y_probs_boot)\n",
    "            scores[\"AUC-PR\"].append(auc(recall_curve, precision_curve))\n",
    "\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    # 4. CI calculation and formatting\n",
    "    alpha = (1.0 - confidence_level) / 2.0\n",
    "    ci_results = {}\n",
    "    for metric_name, metric_scores in scores.items():\n",
    "        if len(metric_scores) == 0:\n",
    "            ci_results[metric_name] = \"N/A\"\n",
    "            continue\n",
    "        \n",
    "        lower_bound = np.percentile(metric_scores, alpha * 100)\n",
    "        upper_bound = np.percentile(metric_scores, (1.0 - alpha) * 100)\n",
    "        mean_score = np.mean(metric_scores)\n",
    "        # results format: mean score ( CI: lower bound ~ upper bound)\n",
    "        ci_results[metric_name] = f\"{mean_score:.6f} ({lower_bound:.6f}-{upper_bound:.6f})\"\n",
    "\n",
    "    print(\"Bootstrapping completed!\")\n",
    "    return ci_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a9b785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 310\n",
      "Classes: ['b-lsa', 't-lsa']\n"
     ]
    }
   ],
   "source": [
    "transforms_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_dir2 = '/blue/jkim19/hyunji.jo/AI_cytology/2025/dataset/patients/classification/tcell_bcell'\n",
    "\n",
    "test_datasets = datasets.ImageFolder(os.path.join(data_dir2, 'test'), transform=transforms_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=8, shuffle=False) ## shuffle=False\n",
    "\n",
    "print('Test dataset size:', len(test_datasets))\n",
    "class_names = test_datasets.classes\n",
    "print('Classes:', class_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a270c3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically extracting patient IDs form filenames for bootstrapping\n",
      "Saving extracted patient IDs to /blue/jkim19/hyunji.jo/AI_cytology/2025/By_Patients/1120_Revision/tcell_bcell/1208_tcell_patient_id_check_for_bootstrapping.csv for verification\n",
      "Save completed. Please check the file to verify the IDs\n",
      "Patient ID list generated. Length: 310\n",
      "Verification successful. Ready for testing!\n",
      "Verification successful. Ready for testing!\n"
     ]
    }
   ],
   "source": [
    "print(\"Automatically extracting patient IDs form filenames for bootstrapping\")\n",
    "\n",
    "# Ex: '011121_383704_01.tif' -> extract '383704'\n",
    "pid_pattern = re.compile(r\"_(\\d{6})\")\n",
    "\n",
    "def extract_pid_from_path(path):\n",
    "    filename = os.path.basename(path)\n",
    "    match = pid_pattern.search(filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        print(f\"PID extraction failed for: {filename}. Using full filename.\")\n",
    "        return filename\n",
    "\n",
    "patient_ids = [extract_pid_from_path(s[0]) for s in test_datasets.samples]\n",
    "\n",
    "model_dir = \"/blue/jkim19/hyunji.jo/AI_cytology/2025/By_Patients/1120_Revision/tcell_bcell\"\n",
    "check_csv_path = os.path.join(model_dir, \"1208_tcell_patient_id_check_for_bootstrapping.csv\")\n",
    "print(f\"Saving extracted patient IDs to {check_csv_path} for verification\")\n",
    "\n",
    "try:\n",
    "    with open(check_csv_path, mode=\"w\", newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"No.\", \"Original Filename\", \"Extracted Patient ID\"])\n",
    "\n",
    "        for i, (sample, pid) in enumerate (zip(test_datasets.samples, patient_ids)):\n",
    "            original_filename = os.path.basename(sample[0])\n",
    "            writer.writerow([i + 1, original_filename, pid])\n",
    "    print(\"Save completed. Please check the file to verify the IDs\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: Failed to save file: {e}\") # e: reason for error\n",
    "\n",
    "total_test_images = len(test_datasets)\n",
    "print(f\"Patient ID list generated. Length: {len(patient_ids)}\")\n",
    "\n",
    "assert len(patient_ids) == total_test_images, \\\n",
    "    f\"Error! NOT same length -> Patient ID list ({len(patient_ids)}) != dataset size ({total_test_images})\"\n",
    "print(\"Verification successful. Ready for testing!\")\n",
    "print(\"Verification successful. Ready for testing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b9d3133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 models for testing\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/blue/jkim19/hyunji.jo/AI_cytology/2025/By_Patients/tcell_bcell/0609_revision/0609_model_saved_epoch100_tb\"\n",
    "model_files = sorted(glob.glob(os.path.join(model_dir, \"model_fold_*_best.pth\")))\n",
    "\n",
    "if not model_files:\n",
    "    print(\"Error! files were not founded\")\n",
    "    exit()\n",
    "print(f\"Found {len(model_files)} models for testing\")\n",
    "\n",
    "fold_dir = \"/blue/jkim19/hyunji.jo/AI_cytology/2025/By_Patients/1120_Revision/tcell_bcell\"\n",
    "result_dir = os.path.join(fold_dir, \"1208_result_plot_REVISED_final\")\n",
    "os.makedirs(result_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03299975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] --- Testing Model: model_fold_10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference model_fold_10: 100%|██████████| 39/39 [01:04<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Patient-level Bootstrapping (1000 iterations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:05<00:00, 170.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping completed!\n",
      "[RESULT WITH 95% CI] model_fold_10\n",
      "  - Bal Acc: 0.644606 (0.461414-0.824477), MCC: 0.298823 (-0.074585-0.685062)\n",
      "  - F1(bin): 0.442468 (0.130235-0.741971), F1(weighted): 0.748542 (0.568959-0.902532)\n",
      "  - AUC-ROC: 0.686953 (0.439362-0.905506), AUC-PR: 0.511456 (0.157283-0.843243)\n",
      "[INFO] Plots saved for model_fold_10\n",
      "\n",
      "[INFO] --- Testing Model: model_fold_1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference model_fold_1: 100%|██████████| 39/39 [00:29<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Patient-level Bootstrapping (1000 iterations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:05<00:00, 173.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping completed!\n",
      "[RESULT WITH 95% CI] model_fold_1\n",
      "  - Bal Acc: 0.705603 (0.505641-0.882742), MCC: 0.386061 (0.010021-0.729685)\n",
      "  - F1(bin): 0.526824 (0.196711-0.797400), F1(weighted): 0.768113 (0.598542-0.906565)\n",
      "  - AUC-ROC: 0.747975 (0.507917-0.959533), AUC-PR: 0.521452 (0.158445-0.907416)\n",
      "[INFO] Plots saved for model_fold_1\n",
      "\n",
      "[INFO] --- Testing Model: model_fold_2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference model_fold_2: 100%|██████████| 39/39 [00:29<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Patient-level Bootstrapping (1000 iterations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:05<00:00, 178.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping completed!\n",
      "[RESULT WITH 95% CI] model_fold_2\n",
      "  - Bal Acc: 0.579272 (0.509865-0.677778), MCC: 0.289969 (0.058727-0.513795)\n",
      "  - F1(bin): 0.271320 (0.062476-0.520927), F1(weighted): 0.741035 (0.543314-0.902141)\n",
      "  - AUC-ROC: 0.653307 (0.406061-0.874247), AUC-PR: 0.475817 (0.157345-0.785983)\n",
      "[INFO] Plots saved for model_fold_2\n",
      "\n",
      "[INFO] --- Testing Model: model_fold_3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference model_fold_3: 100%|██████████| 39/39 [00:27<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Patient-level Bootstrapping (1000 iterations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:05<00:00, 175.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping completed!\n",
      "[RESULT WITH 95% CI] model_fold_3\n",
      "  - Bal Acc: 0.652910 (0.462636-0.828044), MCC: 0.276236 (-0.059569-0.597718)\n",
      "  - F1(bin): 0.451928 (0.169204-0.726282), F1(weighted): 0.722558 (0.563771-0.857084)\n",
      "  - AUC-ROC: 0.712123 (0.472197-0.913901), AUC-PR: 0.531377 (0.138242-0.859579)\n",
      "[INFO] Plots saved for model_fold_3\n",
      "\n",
      "[INFO] --- Testing Model: model_fold_4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference model_fold_4: 100%|██████████| 39/39 [00:28<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Patient-level Bootstrapping (1000 iterations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:05<00:00, 172.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping completed!\n",
      "[RESULT WITH 95% CI] model_fold_4\n",
      "  - Bal Acc: 0.675381 (0.460348-0.845062), MCC: 0.340118 (-0.066375-0.678539)\n",
      "  - F1(bin): 0.493245 (0.161838-0.751547), F1(weighted): 0.752937 (0.560825-0.901097)\n",
      "  - AUC-ROC: 0.708512 (0.429738-0.938060), AUC-PR: 0.453384 (0.121777-0.834765)\n",
      "[INFO] Plots saved for model_fold_4\n",
      "\n",
      "[INFO] --- Testing Model: model_fold_5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference model_fold_5: 100%|██████████| 39/39 [00:27<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Patient-level Bootstrapping (1000 iterations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:05<00:00, 172.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping completed!\n",
      "[RESULT WITH 95% CI] model_fold_5\n",
      "  - Bal Acc: 0.696308 (0.500279-0.873017), MCC: 0.365413 (0.000549-0.723094)\n",
      "  - F1(bin): 0.515982 (0.210515-0.792089), F1(weighted): 0.756097 (0.577300-0.908739)\n",
      "  - AUC-ROC: 0.741291 (0.487008-0.951042), AUC-PR: 0.551958 (0.164625-0.888508)\n",
      "[INFO] Plots saved for model_fold_5\n",
      "\n",
      "[INFO] --- Testing Model: model_fold_6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference model_fold_6: 100%|██████████| 39/39 [00:29<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Patient-level Bootstrapping (1000 iterations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:05<00:00, 178.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping completed!\n",
      "[RESULT WITH 95% CI] model_fold_6\n",
      "  - Bal Acc: 0.589808 (0.481235-0.733333), MCC: 0.284278 (-0.074279-0.600000)\n",
      "  - F1(bin): 0.297957 (0.000000-0.611218), F1(weighted): 0.750157 (0.535701-0.906486)\n",
      "  - AUC-ROC: 0.656883 (0.353684-0.917308), AUC-PR: 0.488936 (0.114836-0.835616)\n",
      "[INFO] Plots saved for model_fold_6\n",
      "\n",
      "[INFO] --- Testing Model: model_fold_7 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference model_fold_7: 100%|██████████| 39/39 [00:33<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Patient-level Bootstrapping (1000 iterations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:05<00:00, 170.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping completed!\n",
      "[RESULT WITH 95% CI] model_fold_7\n",
      "  - Bal Acc: 0.610802 (0.454618-0.776791), MCC: 0.195040 (-0.074965-0.490924)\n",
      "  - F1(bin): 0.399326 (0.164173-0.653903), F1(weighted): 0.684696 (0.549725-0.807554)\n",
      "  - AUC-ROC: 0.673169 (0.431500-0.880898), AUC-PR: 0.438642 (0.150929-0.748605)\n",
      "[INFO] Plots saved for model_fold_7\n",
      "\n",
      "[INFO] --- Testing Model: model_fold_8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference model_fold_8: 100%|██████████| 39/39 [00:27<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Patient-level Bootstrapping (1000 iterations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:05<00:00, 172.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping completed!\n",
      "[RESULT WITH 95% CI] model_fold_8\n",
      "  - Bal Acc: 0.666974 (0.485714-0.843159), MCC: 0.345313 (-0.023354-0.717009)\n",
      "  - F1(bin): 0.478815 (0.149954-0.776182), F1(weighted): 0.765333 (0.584823-0.917015)\n",
      "  - AUC-ROC: 0.730276 (0.485939-0.938921), AUC-PR: 0.564358 (0.144588-0.892633)\n",
      "[INFO] Plots saved for model_fold_8\n",
      "\n",
      "[INFO] --- Testing Model: model_fold_9 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference model_fold_9: 100%|██████████| 39/39 [00:27<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting Patient-level Bootstrapping (1000 iterations)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:05<00:00, 174.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping completed!\n",
      "[RESULT WITH 95% CI] model_fold_9\n",
      "  - Bal Acc: 0.688740 (0.458492-0.871503), MCC: 0.329898 (-0.068911-0.643700)\n",
      "  - F1(bin): 0.494863 (0.147935-0.744533), F1(weighted): 0.730721 (0.558844-0.865569)\n",
      "  - AUC-ROC: 0.712027 (0.434536-0.929472), AUC-PR: 0.489136 (0.109445-0.855591)\n",
      "[INFO] Plots saved for model_fold_9\n",
      "\n",
      "[SUCCESS] All 10-fold test results with 95% CI (including Weighted metrics) saved to /blue/jkim19/hyunji.jo/AI_cytology/2025/By_Patients/tcell_bcell/0609_revision/0609_model_saved_epoch100_tb/1208_TCELL_ResNet50_10Fold_Test_Results_all_CI_Final.csv\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for model_path in model_files:\n",
    "    fold_name = os.path.basename(model_path).replace(\"_best.pth\", \"\")\n",
    "    print(f\"\\n[INFO] --- Testing Model: {fold_name} ---\")\n",
    "\n",
    "    model = models.resnet50(weights='IMAGENET1K_V1')\n",
    "    model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    preds_array = []\n",
    "    y_test = []\n",
    "    y_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_dataloader, desc=f\"Inference {fold_name}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs >= 0.5).float()\n",
    "\n",
    "            preds_array.extend(preds.cpu().numpy())\n",
    "            y_test.extend(labels.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Perform Bootstrapping by patient id & Save\n",
    "    ci_results_str = calculate_bootstrap_ci(y_test, preds_array, y_probs, patient_ids, n_iterations=1000)\n",
    "\n",
    "    accuracy_str = ci_results_str[\"Accuracy\"]\n",
    "    balanced_acc_str = ci_results_str[\"Balanced Accuracy\"]\n",
    "    mcc_str = ci_results_str[\"MCC\"]\n",
    "    sensitivity_str = ci_results_str[\"Sensitivity\"]\n",
    "    specificity_str = ci_results_str[\"Specificity\"]\n",
    "    ppv_str = ci_results_str[\"PPV\"]\n",
    "    npv_str = ci_results_str[\"NPV\"]\n",
    "    f1_binary_str = ci_results_str[\"F1 Score (Binary)\"]\n",
    "\n",
    "    precision_binary_str = ci_results_str[\"Precision (Binary)\"]\n",
    "    auc_roc_str = ci_results_str[\"AUC-ROC\"]\n",
    "    auc_pr_str = ci_results_str[\"AUC-PR\"]\n",
    "\n",
    "    precision_weighted_str = ci_results_str[\"Precision (Weighted)\"]\n",
    "    recall_weighted_str = ci_results_str[\"Recall (Weighted)\"]\n",
    "    f1_weighted_str = ci_results_str[\"F1 Score (Weighted)\"]\n",
    "\n",
    "    print(f\"[RESULT WITH 95% CI] {fold_name}\")\n",
    "    print(f\"  - Bal Acc: {balanced_acc_str}, MCC: {mcc_str}\")\n",
    "    print(f\"  - F1(bin): {f1_binary_str}, F1(weighted): {f1_weighted_str}\")\n",
    "    print(f\"  - AUC-ROC: {auc_roc_str}, AUC-PR: {auc_pr_str}\")\n",
    "    \n",
    "    results.append([\n",
    "        fold_name, \n",
    "        accuracy_str, \n",
    "        balanced_acc_str, \n",
    "        mcc_str, \n",
    "        sensitivity_str,\n",
    "        specificity_str, \n",
    "        ppv_str,\n",
    "        npv_str,\n",
    "        precision_binary_str,\n",
    "        auc_roc_str,\n",
    "        auc_pr_str, \n",
    "        f1_binary_str,\n",
    "        precision_weighted_str, \n",
    "        recall_weighted_str, \n",
    "        f1_weighted_str\n",
    "    ])\n",
    "\n",
    "    incorrect_filenames = []\n",
    "    for i, (y_pred, y) in enumerate(zip(preds_array, y_test)):\n",
    "        if y_pred != y:\n",
    "            filename = test_datasets.samples[i][0]\n",
    "            incorrect_filenames.append((filename, int(y_pred), int(y)))\n",
    "    incorrect_csv_path = os.path.join(result_dir, f\"{fold_name}_incorrect_predictions.csv\")\n",
    "    with open(incorrect_csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File Name\", \"Prediction\", \"Actual\"])\n",
    "        for f, pred, actual in incorrect_filenames:\n",
    "            writer.writerow([os.path.basename(f), class_names[pred], class_names[actual]])\n",
    "\n",
    "    cm_raw = confusion_matrix(y_test, preds_array)\n",
    "    cm_norm = confusion_matrix(y_test, preds_array, normalize='true')\n",
    "\n",
    "    # Standard CM\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_raw, display_labels=class_names)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    disp.plot(ax=ax, cmap='magma', values_format='d')\n",
    "    plt.title(f\"Confusion Matrix - {fold_name}\")\n",
    "    plt.savefig(os.path.join(result_dir, f\"{fold_name}_confusion_matrix.png\"), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Normalized CM\n",
    "    disp_norm = ConfusionMatrixDisplay(confusion_matrix=cm_norm, display_labels=class_names)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    disp_norm.plot(ax=ax, cmap='magma', values_format='.6f')\n",
    "    plt.title(f\"Normalized Confusion Matrix - {fold_name}\")\n",
    "    plt.savefig(os.path.join(result_dir, f\"{fold_name}_confusion_matrix_normalized.png\"), bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"[INFO] Plots saved for {fold_name}\")\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.6f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {fold_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(result_dir, f\"{fold_name}_roc_curve.png\"), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # PR Curve\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_probs)\n",
    "    pr_auc = auc(recall_curve, precision_curve)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(recall_curve, precision_curve, color=\"blue\", lw=2, label=f'PR Curve (AUC = {pr_auc:.6f})')\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(f'Precision-Recall Curve - {fold_name}')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(result_dir, f\"{fold_name}_pr_curve.png\"), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ==================================================================\n",
    "# Final results with 95% CI\n",
    "# ==================================================================\n",
    "result_csv_path = os.path.join(model_dir, \"1208_TCELL_ResNet50_10Fold_Test_Results_all_CI_Final.csv\")\n",
    "with open(result_csv_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    header = [\n",
    "        \"Model (Fold)\", \n",
    "        \"Accuracy (95% CI)\", \n",
    "        \"Balanced Accuracy (95% CI)\", \n",
    "        \"MCC (95% CI)\", \n",
    "        \"Sensitivity (95% CI)\",\n",
    "        \"Specificity (95% CI)\", \n",
    "        \"PPV (95% CI)\",\n",
    "        \"NPV (95% CI)\",\n",
    "        \"Precision (95% CI)\",\n",
    "        \"AUC-ROC (95% CI)\",\n",
    "        \"AUC-PR (95% CI)\", \n",
    "        \"F1 Score (Binary) (95% CI)\", \n",
    "        \"Precision (Weighted) (95% CI)\", \n",
    "        \"Recall (Weighted) (95% CI)\", \n",
    "        \"F1 Score (Weighted) (95% CI)\"\n",
    "    ]\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"\\n[SUCCESS] All 10-fold test results with 95% CI (including Weighted metrics) saved to {result_csv_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51e0551",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cytoCNN",
   "language": "python",
   "name": "cytocnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
